In Anderson's article "The End of Theory: The Data Deluge Makes the Scientific Method Obsolete," he explains that big data has led to the "death of theory."  He explains that with companies like Google that can translate languages without actually knowing them, the need to explain everything has become irrelevant.  Massive amounts of data and applied mathematics replace every scientific method that has been used in the past.  He argues that theories of linguistics, human behavior, psychology, and sociology go out the door when no one cares why people do what they do.  Numbers speak for themselves now.  
 
He explains that due to the massive amount of readily available data, it becomes difficult to build models to explain things.  Petabytes allow us to break the scientific rule of "correlation does not equal causation" by saying that correlation is enough, we can just analyze data without hypotheses about what it might show.  

In Kitchen's article "Big Data, new epistemologies and paradigm shifts," he offers a rebuttle to Anderson.  As a result of big data, there is a lot of ways to analyze data.  Therefore, scientific methods and purpose is important to keep in mind in order to have a focus.  Kitchen believes that rather than a pull away from the scientific method, readily available data causes a greater need for scientific questions to be asked.  He uses the example of Amazon's reccomendation system produces suggestions for other items without knowing anything about the person reading it.  This type of data analytics simply identifies patterns of perchancing, the desire to explain why these associations exist within the data are largely cast as unnecessary.  Because scientists don't usually know about causation, the purpose is more to predict than to understand the world.  In a lot of cases, prediction trumps explanation.  This is a different way of thinking than has been shown in the past.  People care more about what is happening in the future than why things are happening right now. 
